{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76754616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h</th>\n",
       "      <th>w</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>119.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       h  w  class\n",
       "0    6.5  1      2\n",
       "1    8.0  1      0\n",
       "2   61.0  2      1\n",
       "3   54.0  0      1\n",
       "4   78.0  0      1\n",
       "5  119.0  2      2\n",
       "6  111.0  1      2\n",
       "7   23.0  0      0\n",
       "8   31.0  2      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, StratifiedKFold,\\\n",
    "            StratifiedShuffleSplit, GroupKFold, GroupShuffleSplit\n",
    "          \n",
    "          \n",
    "df2 = pd.DataFrame([[6.5, 1, 2],\n",
    "            [8, 1, 0],\n",
    "            [61, 2, 1],\n",
    "            [54, 0, 1],\n",
    "            [78, 0, 1],\n",
    "            [119, 2, 2],\n",
    "            [111, 1, 2],\n",
    "            [23, 0, 0],\n",
    "            [31, 2, 0]], columns=['h', 'w', 'class'])\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fe3656a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold Spliting:\n",
      "Train index: [0 1 3 5 6 8] | test index: [2 4 7]\n",
      "KFold Spliting:\n",
      "Train index: [0 2 3 4 7 8] | test index: [1 5 6]\n",
      "KFold Spliting:\n",
      "Train index: [1 2 4 5 6 7] | test index: [0 3 8]\n"
     ]
    }
   ],
   "source": [
    "X = df2.drop(['class'], axis=1)\n",
    "y = df2['class']\n",
    "\n",
    "#kfold\n",
    "floder = KFold(n_splits=3, random_state=2020, shuffle=True)\n",
    "for train_idx, test_idx in floder.split(X,y):\n",
    "    print(\"KFold Spliting:\")\n",
    "    print('Train index: %s | test index: %s' % (train_idx, test_idx))\n",
    "    # print(X.iloc[train_idx], y.iloc[train_idx], '\\n', X.iloc[test_idx], y.iloc[test_idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f8ebbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold Spliting:\n",
      "Train index: [0 3 4 5 7 8] | test index: [1 2 6]\n",
      "StratifiedKFold Spliting:\n",
      "Train index: [1 2 3 5 6 8] | test index: [0 4 7]\n",
      "StratifiedKFold Spliting:\n",
      "Train index: [0 1 2 4 6 7] | test index: [3 5 8]\n"
     ]
    }
   ],
   "source": [
    "#StratifiedKFold   均匀划分\n",
    "sfolder = StratifiedKFold(n_splits=3, random_state=2020, shuffle=True)\n",
    "for train_idx, test_idx in sfolder.split(X,y):\n",
    "    print(\"StratifiedKFold Spliting:\")\n",
    "    print('Train index: %s | test index: %s' % (train_idx, test_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08dd8228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _BaseKFold.split at 0x000002C416036DD0>\n"
     ]
    }
   ],
   "source": [
    "#StratifiedKFold   均匀划分  \n",
    "sfolder = StratifiedKFold(n_splits=3, random_state=2020, shuffle=True)\n",
    "for train_idx, test_idx in sfolder.split(df2[\"h\"],df2[\"w\"],df2[\"class\"]):\n",
    "    print(\"StratifiedKFold Spliting:\")\n",
    "    print('Train index: %s | test index: %s' % (train_idx, test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b581fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold Spliting:\n",
      "Train index: [0 3 4 5 7 8] | test index: [1 2 6]\n",
      "StratifiedKFold Spliting:\n",
      "Train index: [1 2 3 5 6 8] | test index: [0 4 7]\n",
      "StratifiedKFold Spliting:\n",
      "Train index: [0 1 2 4 6 7] | test index: [3 5 8]\n"
     ]
    }
   ],
   "source": [
    "#StratifiedKFold   均匀划分  \n",
    "sfolder = StratifiedKFold(n_splits=3, random_state=2020, shuffle=True)\n",
    "for train_idx, test_idx in sfolder.split(df2,df2[\"class\"]):\n",
    "    print(\"StratifiedKFold Spliting:\")\n",
    "    print('Train index: %s | test index: %s' % (train_idx, test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55b002e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupKFold Spliting:\n",
      "Train index: [0 1 3 4 6 7] | test index: [2 5 8]\n",
      "GroupKFold Spliting:\n",
      "Train index: [2 3 4 5 7 8] | test index: [0 1 6]\n",
      "GroupKFold Spliting:\n",
      "Train index: [0 1 2 5 6 8] | test index: [3 4 7]\n"
     ]
    }
   ],
   "source": [
    "gfolder = GroupKFold(n_splits=3)\n",
    "for train_idx, test_idx in gfolder.split(X,y, groups=X['w']):\n",
    "    print(\"GroupKFold Spliting:\")\n",
    "    print('Train index: %s | test index: %s' % (train_idx, test_idx))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48d1ba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit Spliting:\n",
      "Train index: [8 2 3 0 6 7] | test index: [1 5 4]\n",
      "StratifiedShuffleSplit Spliting:\n",
      "Train index: [3 1 6 2 7 5] | test index: [8 0 4]\n",
      "StratifiedShuffleSplit Spliting:\n",
      "Train index: [1 8 2 6 0 4] | test index: [7 3 5]\n"
     ]
    }
   ],
   "source": [
    "shuffle_split = StratifiedShuffleSplit(n_splits=3, random_state=2020, test_size=3) #test_size必须比类别大或者 可以重复采样\n",
    "for train_idx, test_idx in shuffle_split.split(X,y):\n",
    "    print(\"StratifiedShuffleSplit Spliting:\")\n",
    "    print('Train index: %s | test index: %s' % (train_idx, test_idx))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b579f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "135                7.7               3.0                6.1               2.3   \n",
      "110                6.5               3.2                5.1               2.0   \n",
      "8                  4.4               2.9                1.4               0.2   \n",
      "122                7.7               2.8                6.7               2.0   \n",
      "26                 5.0               3.4                1.6               0.4   \n",
      "28                 5.2               3.4                1.4               0.2   \n",
      "\n",
      "     target ID  \n",
      "135       2  B  \n",
      "110       2  E  \n",
      "8         0  E  \n",
      "122       2  C  \n",
      "26        0  D  \n",
      "28        0  D  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "def read_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['target'] = iris.target\n",
    "\n",
    "    #新定义一个ID列\n",
    "    list_id = ['A', 'B', 'C', 'D', 'E']\n",
    "    df['ID'] = np.random.choice(list_id, len(df))\n",
    "\n",
    "    features = iris.feature_names\n",
    "    return df, features\n",
    "\n",
    "df, features = read_data()\n",
    "print(df.sample(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5618618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_y(y, groups):\n",
    "    \"\"\"统计每个group里各个y 数目\"\"\"\n",
    "    unique_num = np.max(y) + 1\n",
    "    #key不存在默认返回 np.zeros(unique_num)\n",
    "    y_counts_per_group = defaultdict(lambda : np.zeros(unique_num))\n",
    "\n",
    "    for label, g  in zip(y, groups):\n",
    "        y_counts_per_group[g][label] += 1\n",
    "\n",
    "    # defaultdict(<function__main__.<lambda>>,\n",
    "    # {'A': array([5., 9., 8.]),\n",
    "    # 'B': array([11., 12., 10.]),\n",
    "    # 'C': array([13., 8., 8.]),\n",
    "    # 'D': array([9., 11., 11.]),\n",
    "    # 'E': array([12., 10., 13.])})\n",
    "    return y_counts_per_group\n",
    "\n",
    "def StratiiedGroupKFold(X, y, groups, features, k, seed=None):\n",
    "    \"\"\"\n",
    "    StratiiedGroupKFold数据，yeild划分后数据集索引\n",
    "    :param X: 数据集X\n",
    "    :param y: y target\n",
    "    :param groups: 指定其分布划分的groups\n",
    "    :param features: 特征\n",
    "    :param k: n_split\n",
    "    :param seed:\n",
    "    \"\"\"\n",
    "    max_y = np.max(y)\n",
    "    #得到每个groups y的数目的统计字典\n",
    "    y_counts_per_group = count_y(y, groups)\n",
    "    gf = GroupKFold(n_splits=k)\n",
    "    for train_idx, val_idx in gf.split(X, y, groups):\n",
    "        #分别获取train val划分后数据 以及各自对应的ID列类别数目\n",
    "        x_train = X.iloc[train_idx,:]\n",
    "        #id列类别数目\n",
    "        id_train = x_train['ID'].unique()\n",
    "        x_train = x_train[features]\n",
    "\n",
    "        x_val, y_val = X.iloc[val_idx, :], y.iloc[val_idx]\n",
    "        id_val = x_val['ID'].unique()\n",
    "        x_val = x_val[features]\n",
    "\n",
    "        #统计training dataset 和 validation dataset中y中每个类别数目\n",
    "        y_counts_train = np.zeros(max_y + 1)\n",
    "        y_counts_val = np.zeros(max_y + 1)\n",
    "        for id in id_train:\n",
    "            y_counts_train += y_counts_per_group[id]\n",
    "        for id in id_val:\n",
    "            y_counts_val += y_counts_per_group[id]\n",
    "\n",
    "        #train dataset中按ID列统计y类别相对于最大数目的比例\n",
    "        numratio_train = y_counts_train / np.max(y_counts_train)\n",
    "        #stratified 数目: validation dataset对应y_counts_train最大值索引的count数目 * numratio_train向上取整\n",
    "        stratified_count = np.ceil(y_counts_val[np.argmax(y_counts_train)] * numratio_train).astype(int)\n",
    "\n",
    "        val_idx = np.array([])\n",
    "        np.random.rand(seed)\n",
    "        for num in range(max_y + 1):\n",
    "            val_idx = np.append(val_idx, np.random.choice(y_val[y_val==num].index, stratified_count[num]))\n",
    "        val_idx = val_idx.astype(int)\n",
    "\n",
    "        yield train_idx, val_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eef7e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ID - fold 0:['D' 'B' 'E' 'A']       Test ID - fold 0:['C']\n",
      "Train ID - fold 1:['D' 'B' 'C']       Test ID - fold 1:['A' 'E']\n",
      "Train ID - fold 2:['E' 'A' 'C']       Test ID - fold 2:['D' 'B']\n",
      "                   Label 0  Label 1  Label 2\n",
      "all dataset         33.33%   33.33%   33.33%\n",
      "train set - fold0   36.84%   34.21%   28.95%\n",
      "valid set - fold0   34.78%   34.78%   30.43%\n",
      "train set - fold1   28.89%   34.44%   36.67%\n",
      "valid set - fold1   29.79%   34.04%   36.17%\n",
      "train set - fold2   33.33%   31.25%   35.42%\n",
      "valid set - fold2   34.04%   31.91%   34.04%\n"
     ]
    }
   ],
   "source": [
    "def get_distribution(y_vals):\n",
    "    \"\"\"返回个y各类别的占比\"\"\"\n",
    "    y_distribut = Counter(y_vals)\n",
    "    y_vals_sum = sum(y_distribut.values())\n",
    "    return [f'{y_distribut[i]/y_vals_sum:.2%}' for i in range(np.max(y_vals) + 1)]\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "groups = df['ID']\n",
    "\n",
    "distribution = [get_distribution(y)]\n",
    "index = ['all dataset']\n",
    "\n",
    "#看看划分情况\n",
    "for fold, (train_idx, val_idx) in enumerate(StratiiedGroupKFold(X, y, groups, features, k=3, seed=2020)):\n",
    "    print(f'Train ID - fold {fold:1d}:{groups[train_idx].unique()}\\\n",
    "       Test ID - fold {fold:1d}:{groups[val_idx].unique()}')\n",
    "\n",
    "    distribution.append(get_distribution(y[train_idx]))\n",
    "    index.append(f'train set - fold{fold:1d}')\n",
    "    distribution.append(get_distribution(y[val_idx]))\n",
    "    index.append(f'valid set - fold{fold:1d}')\n",
    "print(pd.DataFrame(distribution, index=index, columns={f' Label{l:2d}' for l in range(np.max(y)+1)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2031e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_group_k_fold(X, y, groups, k, seed=None):\n",
    "    labels_num = np.max(y) + 1\n",
    "    y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n",
    "    y_distr = Counter()\n",
    "    for label, g in zip(y, groups):\n",
    "        y_counts_per_group[g][label] += 1\n",
    "        y_distr[label] += 1\n",
    "\n",
    "    y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n",
    "    groups_per_fold = defaultdict(set)\n",
    "\n",
    "    def eval_y_counts_per_fold(y_counts, fold):\n",
    "        y_counts_per_fold[fold] += y_counts\n",
    "        std_per_label = []\n",
    "        for label in range(labels_num):\n",
    "            label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(k)])\n",
    "            std_per_label.append(label_std)\n",
    "        y_counts_per_fold[fold] -= y_counts\n",
    "        return np.mean(std_per_label)\n",
    "\n",
    "    groups_and_y_counts = list(y_counts_per_group.items())\n",
    "    random.Random(seed).shuffle(groups_and_y_counts)\n",
    "\n",
    "    for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n",
    "        best_fold = None\n",
    "        min_eval = None\n",
    "        for i in range(k):\n",
    "            fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
    "            if min_eval is None or fold_eval < min_eval:\n",
    "                min_eval = fold_eval\n",
    "                best_fold = i\n",
    "        y_counts_per_fold[best_fold] += y_counts\n",
    "        groups_per_fold[best_fold].add(g)\n",
    "\n",
    "    all_groups = set(groups)\n",
    "    for i in range(k):\n",
    "        train_groups = all_groups - groups_per_fold[i]\n",
    "        test_groups = groups_per_fold[i]\n",
    "\n",
    "        train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "        test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n",
    "\n",
    "        yield train_indices, test_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "528c67d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StratiiedGroupKFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m index \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall dataset\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#看看划分情况\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_idx, val_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mStratiiedGroupKFold\u001b[49m(X, y, groups, features, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2020\u001b[39m)):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain ID - fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m1d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroups[train_idx]\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m       Test ID - fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m1d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroups[val_idx]\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m     distribution\u001b[38;5;241m.\u001b[39mappend(get_distribution(y[train_idx]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StratiiedGroupKFold' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5622989b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \n",
      "Get your W&B access token from here: https://wandb.ai/authorize\n",
      "2ae37raizona\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "kfold  discourse_effectiveness\n",
       "0      0                          4196\n",
       "       1                          1865\n",
       "       2                          1292\n",
       "1      0                          4196\n",
       "       1                          1865\n",
       "       2                          1292\n",
       "2      0                          4195\n",
       "       1                          1865\n",
       "       2                          1293\n",
       "3      0                          4195\n",
       "       1                          1865\n",
       "       2                          1293\n",
       "4      0                          4195\n",
       "       1                          1866\n",
       "       2                          1292\n",
       "Name: discourse_effectiveness, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import joblib\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold, KFold,StratifiedKFold,StratifiedGroupKFold\n",
    "from sklearn.metrics import f1_score, log_loss\n",
    "# For Transformer Models\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, AdamW\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "b_ = Fore.BLUE\n",
    "y_ = Fore.YELLOW\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# %%\n",
    "import wandb\n",
    "\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "    user_secrets = UserSecretsClient()\n",
    "    api_key = user_secrets.get_secret(\"wandb_api\")\n",
    "    wandb.login(key=api_key)\n",
    "    anony = None\n",
    "except:\n",
    "    anony = \"must\"\n",
    "    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your '\n",
    "          'W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token '\n",
    "          'from here: https://wandb.ai/authorize')\n",
    "\n",
    "\n",
    "# %%\n",
    "def id_generator(size=12, chars=string.ascii_lowercase + string.digits):\n",
    "    return ''.join(random.SystemRandom().choice(chars) for _ in range(size))\n",
    "\n",
    "\n",
    "HASH_NAME = id_generator(size=12)\n",
    "print(HASH_NAME)\n",
    "# %%\n",
    "TRAIN_DIR = \"feedback-prize-effectiveness/train\"\n",
    "TEST_DIR = \"feedback-prize-effectiveness/test\"\n",
    "# %%\n",
    "CONFIG = {\"seed\": 42,\n",
    "          \"epochs\": 3,\n",
    "          \"model_name\": \"microsoft/deberta-v3-base\",\n",
    "          \"train_batch_size\": 8,\n",
    "          \"valid_batch_size\": 16,\n",
    "          \"max_length\": 512,\n",
    "          \"learning_rate\": 1e-5,\n",
    "          \"scheduler\": 'CosineAnnealingLR',\n",
    "          \"min_lr\": 1e-6,\n",
    "          \"T_max\": 500,\n",
    "          \"weight_decay\": 1e-6,\n",
    "          \"n_fold\": 5,\n",
    "          \"n_accumulate\": 1,\n",
    "          \"num_classes\": 3,\n",
    "          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "          \"hash_name\": HASH_NAME,\n",
    "          \"competition\": \"FeedBack\",\n",
    "          \"_wandb_kernel\": \"deb\",\n",
    "          \"fc_dropout\":0.2,\n",
    "          \"gradient_checkpoint\" : True,\n",
    "          }\n",
    "# num_workers = 1\n",
    "# path = \"../input/feedback-deberta-large-051/\"\n",
    "# config_path = path + 'config.pth'\n",
    "# model = \"microsoft/deberta-large\"\n",
    "# batch_size = 16\n",
    "# fc_dropout = 0.2\n",
    "# target_size = 3\n",
    "# max_len = 512\n",
    "# seed = 42\n",
    "# n_fold = 4\n",
    "# trn_fold = [i for i in range(n_fold)]\n",
    "# gradient_checkpoint = False\n",
    "CONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\n",
    "CONFIG['group'] = f'{HASH_NAME}-Baseline'\n",
    "\n",
    "\n",
    "# %%\n",
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "\n",
    "set_seed(CONFIG['seed'])\n",
    "\n",
    "\n",
    "# %%\n",
    "def get_essay(essay_id):\n",
    "    essay_path = os.path.join(TRAIN_DIR, f\"{essay_id}.txt\")\n",
    "    essay_text = open(essay_path, 'r').read()\n",
    "    return essay_text\n",
    "\n",
    "\n",
    "# %%\n",
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "    assert len(z.shape) == 2\n",
    "    s = np.max(z, axis=1)\n",
    "    s = s[:, np.newaxis] # necessary step to do broadcasting\n",
    "    e_x = np.exp(z - s)\n",
    "    div = np.sum(e_x, axis=1)\n",
    "    div = div[:, np.newaxis] # dito\n",
    "    return e_x / div\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    y_pred = softmax(y_pred)\n",
    "    score = log_loss(y_true, y_pred)\n",
    "    return round(score, 5)\n",
    "df = pd.read_csv(\"feedback-prize-effectiveness/train.csv\")\n",
    "df['essay_text'] = df['essay_id'].apply(get_essay)\n",
    "df.head()\n",
    "\n",
    "# %%\n",
    "# %%\n",
    "\n",
    "# gkf = GroupKFold(n_splits=CONFIG['n_fold'])\n",
    "#\n",
    "# for fold, (_, val_) in enumerate(gkf.split(X=df, groups=df.essay_id)):\n",
    "#     df.loc[val_, \"kfold\"] = int(fold)\n",
    "#\n",
    "# df[\"kfold\"] = df[\"kfold\"].astype(int)\n",
    "# df.head()\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "from text_unidecode import unidecode\n",
    "from typing import Dict, List, Tuple\n",
    "import codecs\n",
    "\n",
    "def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n",
    "    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n",
    "\n",
    "\n",
    "def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n",
    "    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n",
    "\n",
    "# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n",
    "codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n",
    "codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n",
    "\n",
    "def resolve_encodings_and_normalize(text: str) -> str:\n",
    "    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n",
    "    text = (\n",
    "        text.encode(\"raw_unicode_escape\")\n",
    "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n",
    "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "    )\n",
    "    text = unidecode(text)\n",
    "    return text\n",
    "df['discourse_text'] = df['discourse_text'].apply(lambda x : resolve_encodings_and_normalize(x))\n",
    "df['essay_text'] = df['essay_text'].apply(lambda x : resolve_encodings_and_normalize(x))\n",
    "encoder = LabelEncoder()\n",
    "df['discourse_effectiveness'] = encoder.fit_transform(df['discourse_effectiveness'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba75373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kfold  discourse_effectiveness\n",
       "0      0                          4196\n",
       "       1                          1865\n",
       "       2                          1292\n",
       "1      0                          4196\n",
       "       1                          1865\n",
       "       2                          1292\n",
       "2      0                          4195\n",
       "       1                          1865\n",
       "       2                          1293\n",
       "3      0                          4195\n",
       "       1                          1865\n",
       "       2                          1293\n",
       "4      0                          4195\n",
       "       1                          1866\n",
       "       2                          1292\n",
       "Name: discourse_effectiveness, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fold = StratifiedKFold(n_splits=CONFIG['n_fold'], shuffle=True, random_state=CONFIG['seed'])\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(df, df.discourse_effectiveness)):\n",
    "    df.loc[val_index, 'kfold'] = int(n)\n",
    "df['kfold'] = df['kfold'].astype(int)\n",
    "df.groupby('kfold')['discourse_effectiveness'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b60a58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kfold  discourse_effectiveness\n",
       "0      0                          4196\n",
       "       1                          1865\n",
       "       2                          1292\n",
       "1      0                          4196\n",
       "       1                          1865\n",
       "       2                          1292\n",
       "2      0                          4195\n",
       "       1                          1865\n",
       "       2                          1293\n",
       "3      0                          4195\n",
       "       1                          1865\n",
       "       2                          1293\n",
       "4      0                          4195\n",
       "       1                          1866\n",
       "       2                          1292\n",
       "Name: discourse_effectiveness, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fold = StratifiedKFold(n_splits=CONFIG['n_fold'], shuffle=True, random_state=CONFIG['seed'])\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(df.index, df.discourse_effectiveness, df.essay_id)):\n",
    "    df.loc[val_index, 'kfold'] = int(n)\n",
    "df['kfold'] = df['kfold'].astype(int)\n",
    "df.groupby('kfold')['discourse_effectiveness'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26899b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kfold  discourse_effectiveness\n",
       "0      0                          4201\n",
       "       1                          1835\n",
       "       2                          1290\n",
       "1      0                          4277\n",
       "       1                          1733\n",
       "       2                          1307\n",
       "2      0                          4051\n",
       "       1                          1958\n",
       "       2                          1363\n",
       "3      0                          4349\n",
       "       1                          1825\n",
       "       2                          1248\n",
       "4      0                          4099\n",
       "       1                          1975\n",
       "       2                          1254\n",
       "Name: discourse_effectiveness, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Fold = StratifiedGroupKFold(n_splits=CONFIG['n_fold'], shuffle=True, random_state=CONFIG['seed'])\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(df.index, df.discourse_effectiveness, df.essay_id)):\n",
    "    df.loc[val_index, 'kfold'] = int(n)\n",
    "df['kfold'] = df['kfold'].astype(int)\n",
    "df.groupby('kfold')['discourse_effectiveness'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3c9594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch_transformer]",
   "language": "python",
   "name": "conda-env-torch_transformer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
