{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa9c3c43",
   "metadata": {
    "papermill": {
     "duration": 0.018333,
     "end_time": "2022-06-28T02:14:25.040700",
     "exception": false,
     "start_time": "2022-06-28T02:14:25.022367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3>ðŸ“Œ Train Notebook:</h3> <h4><a href='https://www.kaggle.com/code/debarshichanda/pytorch-feedback-deberta-v3-baseline'>https://www.kaggle.com/code/debarshichanda/pytorch-feedback-deberta-v3-baseline</a></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9235f789",
   "metadata": {
    "papermill": {
     "duration": 0.016892,
     "end_time": "2022-06-28T02:14:25.074846",
     "exception": false,
     "start_time": "2022-06-28T02:14:25.057954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* cv0.6819\n",
    "* lb:652\n",
    "* here code:https://www.kaggle.com/code/quincyqiang/feedback-meanpoolingv2-inference\n",
    "* thanks to:Debarshi Chanda\n",
    "* hitsï¼šBased on the baseline, trying the way of text splicing:add `discourse_type` and training on 5folds\n",
    "\n",
    "```\n",
    "text = discourse_type+self.tokenizer.sep_token+discourse +self.tokenizer.sep_token + \" \" + essay\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecd1ccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:14:25.110806Z",
     "iopub.status.busy": "2022-06-28T02:14:25.110052Z",
     "iopub.status.idle": "2022-06-28T02:14:32.453634Z",
     "shell.execute_reply": "2022-06-28T02:14:32.452895Z"
    },
    "papermill": {
     "duration": 7.364284,
     "end_time": "2022-06-28T02:14:32.455865",
     "exception": false,
     "start_time": "2022-06-28T02:14:25.091581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# For Transformer Models\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98d3a716",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:14:32.492703Z",
     "iopub.status.busy": "2022-06-28T02:14:32.492476Z",
     "iopub.status.idle": "2022-06-28T02:14:32.496417Z",
     "shell.execute_reply": "2022-06-28T02:14:32.495716Z"
    },
    "papermill": {
     "duration": 0.024446,
     "end_time": "2022-06-28T02:14:32.498038",
     "exception": false,
     "start_time": "2022-06-28T02:14:32.473592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_DIR='../input/debertalargefold5mp'\n",
    "MODEL_PATHS = [\n",
    "    f'{MODEL_DIR}/Loss-Fold-0.bin',\n",
    "    f'{MODEL_DIR}/Loss-Fold-1.bin',\n",
    "    f'{MODEL_DIR}/Loss-Fold-2.bin',\n",
    "    f'{MODEL_DIR}/Loss-Fold-3.bin',\n",
    "    f'{MODEL_DIR}/Loss-Fold-4.bin',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca8d677",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:14:32.534340Z",
     "iopub.status.busy": "2022-06-28T02:14:32.534125Z",
     "iopub.status.idle": "2022-06-28T02:14:32.538865Z",
     "shell.execute_reply": "2022-06-28T02:14:32.538192Z"
    },
    "papermill": {
     "duration": 0.025857,
     "end_time": "2022-06-28T02:14:32.540534",
     "exception": false,
     "start_time": "2022-06-28T02:14:32.514677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"../input/feedback-prize-effectiveness/train\"\n",
    "TEST_DIR = \"../input/feedback-prize-effectiveness/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4807bb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:14:32.575389Z",
     "iopub.status.busy": "2022-06-28T02:14:32.575166Z",
     "iopub.status.idle": "2022-06-28T02:14:33.361603Z",
     "shell.execute_reply": "2022-06-28T02:14:33.360855Z"
    },
    "papermill": {
     "duration": 0.806609,
     "end_time": "2022-06-28T02:14:33.363821",
     "exception": false,
     "start_time": "2022-06-28T02:14:32.557212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "CONFIG = dict(\n",
    "    seed = 42,\n",
    "    model_name = '../input/deberta-v3-large/deberta-v3-large',\n",
    "    test_batch_size = 16,\n",
    "    max_length = 512,\n",
    "    num_classes = 3,\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "\n",
    "CONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88aa6cd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:14:33.400041Z",
     "iopub.status.busy": "2022-06-28T02:14:33.399779Z",
     "iopub.status.idle": "2022-06-28T02:14:33.404313Z",
     "shell.execute_reply": "2022-06-28T02:14:33.403507Z"
    },
    "papermill": {
     "duration": 0.024519,
     "end_time": "2022-06-28T02:14:33.406126",
     "exception": false,
     "start_time": "2022-06-28T02:14:33.381607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_essay(essay_id):\n",
    "    essay_path = os.path.join(TEST_DIR, f\"{essay_id}.txt\")\n",
    "    essay_text = open(essay_path, 'r').read()\n",
    "    return essay_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71107a7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:14:33.442453Z",
     "iopub.status.busy": "2022-06-28T02:14:33.442220Z",
     "iopub.status.idle": "2022-06-28T02:14:33.493674Z",
     "shell.execute_reply": "2022-06-28T02:14:33.492862Z"
    },
    "papermill": {
     "duration": 0.072321,
     "end_time": "2022-06-28T02:14:33.495715",
     "exception": false,
     "start_time": "2022-06-28T02:14:33.423394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>essay_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Seeking multiple opinions can help a person ma...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9790d835736b</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>it can decrease stress levels</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75ce6d68b67b</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>a great chance to learn something new</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93578d946723</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>can be very helpful and beneficial.</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  a261b6e14276  D72CB1C11673   \n",
       "1  5a88900e7dc1  D72CB1C11673   \n",
       "2  9790d835736b  D72CB1C11673   \n",
       "3  75ce6d68b67b  D72CB1C11673   \n",
       "4  93578d946723  D72CB1C11673   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Making choices in life can be very difficult. ...           Lead   \n",
       "1  Seeking multiple opinions can help a person ma...       Position   \n",
       "2                     it can decrease stress levels           Claim   \n",
       "3             a great chance to learn something new           Claim   \n",
       "4               can be very helpful and beneficial.           Claim   \n",
       "\n",
       "                                          essay_text  \n",
       "0  Making choices in life can be very difficult. ...  \n",
       "1  Making choices in life can be very difficult. ...  \n",
       "2  Making choices in life can be very difficult. ...  \n",
       "3  Making choices in life can be very difficult. ...  \n",
       "4  Making choices in life can be very difficult. ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../input/feedback-prize-effectiveness/test.csv\")\n",
    "df['essay_text'] = df['essay_id'].apply(get_essay)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a2a28c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:14:33.533262Z",
     "iopub.status.busy": "2022-06-28T02:14:33.532863Z",
     "iopub.status.idle": "2022-06-28T02:14:34.062560Z",
     "shell.execute_reply": "2022-06-28T02:14:34.061838Z"
    },
    "papermill": {
     "duration": 0.550736,
     "end_time": "2022-06-28T02:14:34.065119",
     "exception": false,
     "start_time": "2022-06-28T02:14:33.514383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.1.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Adequate', 'Effective', 'Ineffective'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"../input/{MODEL_DIR}/le.pkl\", \"rb\") as fp:\n",
    "    encoder = joblib.load(fp)\n",
    "    \n",
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c2c3ade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:14:34.103884Z",
     "iopub.status.busy": "2022-06-28T02:14:34.103258Z",
     "iopub.status.idle": "2022-06-28T02:14:34.111767Z",
     "shell.execute_reply": "2022-06-28T02:14:34.111104Z"
    },
    "papermill": {
     "duration": 0.030151,
     "end_time": "2022-06-28T02:14:34.113456",
     "exception": false,
     "start_time": "2022-06-28T02:14:34.083305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedBackDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.discourse_type = df['discourse_type'].values\n",
    "        self.discourse = df['discourse_text'].values\n",
    "        self.essay = df['essay_text'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        discourse_type = self.discourse_type[index]\n",
    "        discourse = self.discourse[index]\n",
    "        \n",
    "        essay = self.essay[index]\n",
    "        text = discourse_type+self.tokenizer.sep_token+discourse +self.tokenizer.sep_token + \" \" + essay\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        truncation=True,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=self.max_len,\n",
    "                        padding='max_length'\n",
    "                    )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2e68a94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:14:34.150682Z",
     "iopub.status.busy": "2022-06-28T02:14:34.150134Z",
     "iopub.status.idle": "2022-06-28T02:14:34.154688Z",
     "shell.execute_reply": "2022-06-28T02:14:34.154022Z"
    },
    "papermill": {
     "duration": 0.024931,
     "end_time": "2022-06-28T02:14:34.156298",
     "exception": false,
     "start_time": "2022-06-28T02:14:34.131367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = FeedBackDataset(df, CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['test_batch_size'],\n",
    "                         num_workers=2, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b380f31e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:14:34.194404Z",
     "iopub.status.busy": "2022-06-28T02:14:34.193882Z",
     "iopub.status.idle": "2022-06-28T02:14:34.199448Z",
     "shell.execute_reply": "2022-06-28T02:14:34.198795Z"
    },
    "papermill": {
     "duration": 0.026479,
     "end_time": "2022-06-28T02:14:34.201123",
     "exception": false,
     "start_time": "2022-06-28T02:14:34.174644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eaa2767",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:14:34.238075Z",
     "iopub.status.busy": "2022-06-28T02:14:34.237526Z",
     "iopub.status.idle": "2022-06-28T02:14:34.243826Z",
     "shell.execute_reply": "2022-06-28T02:14:34.243170Z"
    },
    "papermill": {
     "duration": 0.02663,
     "end_time": "2022-06-28T02:14:34.245534",
     "exception": false,
     "start_time": "2022-06-28T02:14:34.218904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedBackModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(FeedBackModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        self.drop = nn.Dropout(p=0.1)\n",
    "        self.pooler = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, CONFIG['num_classes'])\n",
    "        \n",
    "    def forward(self, ids, mask):        \n",
    "        out = self.model(input_ids=ids,attention_mask=mask,\n",
    "                         output_hidden_states=False)\n",
    "        out = self.pooler(out.last_hidden_state, mask)\n",
    "        out = self.drop(out)\n",
    "        outputs = self.fc(out)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a59dd4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:14:34.282774Z",
     "iopub.status.busy": "2022-06-28T02:14:34.282099Z",
     "iopub.status.idle": "2022-06-28T02:14:34.289042Z",
     "shell.execute_reply": "2022-06-28T02:14:34.288357Z"
    },
    "papermill": {
     "duration": 0.027319,
     "end_time": "2022-06-28T02:14:34.290743",
     "exception": false,
     "start_time": "2022-06-28T02:14:34.263424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    PREDS = []\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        \n",
    "        outputs = model(ids, mask)\n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        PREDS.append(outputs.cpu().detach().numpy()) \n",
    "    \n",
    "    PREDS = np.concatenate(PREDS)\n",
    "    gc.collect()\n",
    "    \n",
    "    return PREDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "634f76b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:14:34.329241Z",
     "iopub.status.busy": "2022-06-28T02:14:34.328741Z",
     "iopub.status.idle": "2022-06-28T02:14:34.334463Z",
     "shell.execute_reply": "2022-06-28T02:14:34.333699Z"
    },
    "papermill": {
     "duration": 0.026934,
     "end_time": "2022-06-28T02:14:34.336385",
     "exception": false,
     "start_time": "2022-06-28T02:14:34.309451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(model_paths, dataloader, device):\n",
    "    final_preds = []\n",
    "    for i, path in enumerate(model_paths):\n",
    "        model = FeedBackModel(CONFIG['model_name'])\n",
    "        model.to(CONFIG['device'])\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        \n",
    "        print(f\"Getting predictions for model {i+1}\")\n",
    "        preds = valid_fn(model, dataloader, device)\n",
    "        final_preds.append(preds)\n",
    "    \n",
    "    final_preds = np.array(final_preds)\n",
    "    final_preds = np.mean(final_preds, axis=0)\n",
    "    return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "121b72cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:14:34.374026Z",
     "iopub.status.busy": "2022-06-28T02:14:34.373436Z",
     "iopub.status.idle": "2022-06-28T02:16:43.054469Z",
     "shell.execute_reply": "2022-06-28T02:16:43.053560Z"
    },
    "papermill": {
     "duration": 128.702515,
     "end_time": "2022-06-28T02:16:43.056901",
     "exception": false,
     "start_time": "2022-06-28T02:14:34.354386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/deberta-v3-large/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifer.weight', 'mask_predictions.classifer.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions for model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.97s/it]\n",
      "Some weights of the model checkpoint at ../input/deberta-v3-large/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifer.weight', 'mask_predictions.classifer.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions for model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Some weights of the model checkpoint at ../input/deberta-v3-large/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifer.weight', 'mask_predictions.classifer.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions for model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.07s/it]\n",
      "Some weights of the model checkpoint at ../input/deberta-v3-large/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifer.weight', 'mask_predictions.classifer.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions for model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.05s/it]\n",
      "Some weights of the model checkpoint at ../input/deberta-v3-large/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifer.weight', 'mask_predictions.classifer.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions for model 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "preds = inference(MODEL_PATHS, test_loader, CONFIG['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "388eec2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:16:43.115633Z",
     "iopub.status.busy": "2022-06-28T02:16:43.115401Z",
     "iopub.status.idle": "2022-06-28T02:16:43.121256Z",
     "shell.execute_reply": "2022-06-28T02:16:43.120557Z"
    },
    "papermill": {
     "duration": 0.037622,
     "end_time": "2022-06-28T02:16:43.123160",
     "exception": false,
     "start_time": "2022-06-28T02:16:43.085538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48266315, 0.5032471 , 0.01408979],\n",
       "       [0.8326214 , 0.10760152, 0.05977707],\n",
       "       [0.70272607, 0.26578256, 0.03149139],\n",
       "       [0.7942687 , 0.14342931, 0.06230202],\n",
       "       [0.728241  , 0.23504177, 0.03671721],\n",
       "       [0.5505398 , 0.42390838, 0.02555186],\n",
       "       [0.45584708, 0.5271238 , 0.0170291 ],\n",
       "       [0.7156738 , 0.25182486, 0.03250138],\n",
       "       [0.49571452, 0.47771677, 0.02656874],\n",
       "       [0.72892225, 0.21936813, 0.05170959]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c3cf74e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:16:43.182043Z",
     "iopub.status.busy": "2022-06-28T02:16:43.181383Z",
     "iopub.status.idle": "2022-06-28T02:16:43.199417Z",
     "shell.execute_reply": "2022-06-28T02:16:43.198676Z"
    },
    "papermill": {
     "duration": 0.048736,
     "end_time": "2022-06-28T02:16:43.201172",
     "exception": false,
     "start_time": "2022-06-28T02:16:43.152436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective</th>\n",
       "      <th>Adequate</th>\n",
       "      <th>Effective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9790d835736b</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75ce6d68b67b</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93578d946723</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective  Adequate  Effective\n",
       "0  a261b6e14276         0.20      0.60       0.40\n",
       "1  5a88900e7dc1         3.00      6.00       1.00\n",
       "2  9790d835736b         1.00      2.00       3.00\n",
       "3  75ce6d68b67b         0.33      0.34       0.33\n",
       "4  93578d946723         0.01      0.24       0.47"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv(\"../input/feedback-prize-effectiveness/sample_submission.csv\")\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc7e61d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:16:43.262470Z",
     "iopub.status.busy": "2022-06-28T02:16:43.261791Z",
     "iopub.status.idle": "2022-06-28T02:16:43.277201Z",
     "shell.execute_reply": "2022-06-28T02:16:43.276500Z"
    },
    "papermill": {
     "duration": 0.047019,
     "end_time": "2022-06-28T02:16:43.278902",
     "exception": false,
     "start_time": "2022-06-28T02:16:43.231883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective</th>\n",
       "      <th>Adequate</th>\n",
       "      <th>Effective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.014090</td>\n",
       "      <td>0.482663</td>\n",
       "      <td>0.503247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.059777</td>\n",
       "      <td>0.832621</td>\n",
       "      <td>0.107602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9790d835736b</td>\n",
       "      <td>0.031491</td>\n",
       "      <td>0.702726</td>\n",
       "      <td>0.265783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75ce6d68b67b</td>\n",
       "      <td>0.062302</td>\n",
       "      <td>0.794269</td>\n",
       "      <td>0.143429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93578d946723</td>\n",
       "      <td>0.036717</td>\n",
       "      <td>0.728241</td>\n",
       "      <td>0.235042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective  Adequate  Effective\n",
       "0  a261b6e14276     0.014090  0.482663   0.503247\n",
       "1  5a88900e7dc1     0.059777  0.832621   0.107602\n",
       "2  9790d835736b     0.031491  0.702726   0.265783\n",
       "3  75ce6d68b67b     0.062302  0.794269   0.143429\n",
       "4  93578d946723     0.036717  0.728241   0.235042"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['Adequate'] = preds[:, 0]\n",
    "sample['Effective'] = preds[:, 1]\n",
    "sample['Ineffective'] = preds[:, 2]\n",
    "\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "334db654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:16:43.337912Z",
     "iopub.status.busy": "2022-06-28T02:16:43.337693Z",
     "iopub.status.idle": "2022-06-28T02:16:43.345133Z",
     "shell.execute_reply": "2022-06-28T02:16:43.344479Z"
    },
    "papermill": {
     "duration": 0.038511,
     "end_time": "2022-06-28T02:16:43.346822",
     "exception": false,
     "start_time": "2022-06-28T02:16:43.308311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 149.63566,
   "end_time": "2022-06-28T02:16:46.231929",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-28T02:14:16.596269",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
